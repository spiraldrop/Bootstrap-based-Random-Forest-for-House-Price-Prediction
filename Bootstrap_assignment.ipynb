{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3sNKZq4XrXQh"
   },
   "source": [
    "# <font color='red'><b>Bootstrap assignment</b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RAHap1Z3FZC-"
   },
   "source": [
    "<b>There will be some functions that start with the word \"grader\" ex: grader_sampples(), grader_30().. etc, you should not change those function definition.\n",
    "\n",
    "Every Grader function has to return True.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cuxBq_bvrwh2"
   },
   "source": [
    "<font color='blue'> <b>Importing packages</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m6ag91ijrQOs"
   },
   "outputs": [],
   "source": [
    "import numpy as np # importing numpy for numerical computation\n",
    "from sklearn.datasets import load_boston # here we are using sklearn's boston dataset\n",
    "from sklearn.metrics import mean_squared_error # importing mean_squared_error metric\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CcHOsONTt1K_"
   },
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "x=boston.data #independent variables\n",
    "y=boston.target #target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pc1htEFYuLRj",
    "outputId": "f5b60712-98b3-4cdc-b629-3546c1e3859c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "kQle3T_wuOa3",
    "outputId": "521c7bdd-5316-48d5-c534-b61d170d2c28"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.3200e-03, 1.8000e+01, 2.3100e+00, 0.0000e+00, 5.3800e-01,\n",
       "        6.5750e+00, 6.5200e+01, 4.0900e+00, 1.0000e+00, 2.9600e+02,\n",
       "        1.5300e+01, 3.9690e+02, 4.9800e+00],\n",
       "       [2.7310e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01,\n",
       "        6.4210e+00, 7.8900e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02,\n",
       "        1.7800e+01, 3.9690e+02, 9.1400e+00],\n",
       "       [2.7290e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01,\n",
       "        7.1850e+00, 6.1100e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02,\n",
       "        1.7800e+01, 3.9283e+02, 4.0300e+00],\n",
       "       [3.2370e-02, 0.0000e+00, 2.1800e+00, 0.0000e+00, 4.5800e-01,\n",
       "        6.9980e+00, 4.5800e+01, 6.0622e+00, 3.0000e+00, 2.2200e+02,\n",
       "        1.8700e+01, 3.9463e+02, 2.9400e+00],\n",
       "       [6.9050e-02, 0.0000e+00, 2.1800e+00, 0.0000e+00, 4.5800e-01,\n",
       "        7.1470e+00, 5.4200e+01, 6.0622e+00, 3.0000e+00, 2.2200e+02,\n",
       "        1.8700e+01, 3.9690e+02, 5.3300e+00]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AEa_HqRZloH4"
   },
   "source": [
    "## <font color='red'><b>Task 1</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YQ5q8IxHNRk3"
   },
   "source": [
    "<font color='red'> <b>Step - 1</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GJCFCaOzl7Mr"
   },
   "source": [
    "*  <font color='blue'><b>Creating samples</b></font><br>\n",
    "    <b> Randomly create 30 samples from the whole boston data points</b>\n",
    "    *  Creating each sample: Consider any random 303(60% of 506) data points from whole data set and then replicate any 203 points from the sampled points\n",
    "    \n",
    "     For better understanding of this procedure lets check this examples, assume we have 10 data points [1,2,3,4,5,6,7,8,9,10], first we take 6 data points randomly , consider we have selected [4, 5, 7, 8, 9, 3] now we will replicate 4 points from [4, 5, 7, 8, 9, 3], consder they are [5, 8, 3,7] so our final sample will be [4, 5, 7, 8, 9, 3, 5, 8, 3,7]\n",
    "* <font color='blue'><b> Create 30 samples </b></font>\n",
    "    *  Note that as a part of the Bagging when you are taking the random samples <b>make sure each of the sample will have different set of columns</b><br>\n",
    "Ex: Assume we have 10 columns[1 ,2 ,3 ,4 ,5 ,6 ,7 ,8 ,9 ,10] for the first sample we will select [3, 4, 5, 9, 1, 2] and for the second sample  [7, 9, 1, 4, 5, 6, 2] and so on...\n",
    "Make sure each sample will have atleast 3 feautres/columns/attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zUqFEBSvNjCa"
   },
   "source": [
    "<font color='red'><b>Step - 2 </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uqi9AhCYNq3Z"
   },
   "source": [
    "<font color='blue'><b>Building High Variance Models on each of the sample and finding train MSE value</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lLBnZHXOFln"
   },
   "source": [
    "*  Build a regression trees on each of 30 samples.\n",
    "*  Computed the predicted values of each data point(506 data points) in your corpus.\n",
    "*  Predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{30}\\sum_{k=1}^{30}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$\n",
    "*  Now calculate the $MSE =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kls23JLnSN23"
   },
   "source": [
    "<font color='red'> <b>Step - 3 </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rz2GchkGSWnh"
   },
   "source": [
    "*  <font color='blue'><b>Calculating the OOB score </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DGHkVV2kSibm"
   },
   "source": [
    "*  Predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{k}\\sum_{\\text{k= model which was buit on samples not included } x^{i}}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$.\n",
    "*  Now calculate the $OOB Score =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RK860ocxTyoz"
   },
   "source": [
    "# <font color='red'><b>Task 2</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1dme-N6TUCrY"
   },
   "source": [
    "*  <font color='blue'><b>Computing CI of OOB Score and Train MSE</b></font>\n",
    "  *   Repeat Task 1 for 35 times, and for each iteration store the Train MSE and OOB score </li>\n",
    "<li> After this we will have 35 Train MSE values and 35 OOB scores </li>\n",
    "<li> using these 35 values (assume like a sample) find the confidence intravels of MSE and OOB Score </li>\n",
    "<li> you need to report CI of MSE and CI of OOB Score </li>\n",
    "<li> Note: Refer the Central_Limit_theorem.ipynb to check how to find the confidence intravel</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O6UcH1x9Uwrj"
   },
   "source": [
    "# <font color='red'><b>Task 3</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bOC_AgsLU7OH"
   },
   "source": [
    "*  <font color='blue'><b>Given a single query point predict the price of house.</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HYs5jSFdVILe"
   },
   "source": [
    "Consider xq= [0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60] \n",
    "Predict the house price for this point as mentioned in the step 2 of Task 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_6gxZEsFWm-8"
   },
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V2fHTdS_zpgG"
   },
   "source": [
    "# <font color='blue'> <b>Task - 1</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e0yGBuryOwHz"
   },
   "source": [
    "<font color='blue'><b>Step - 1</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lJXX8vf3z073"
   },
   "source": [
    "*  <font color='blue'> <b>Creating samples</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CSVaWG1F4uCZ"
   },
   "source": [
    "<font color='Orange'><b>Algorithm</b></font>\n",
    "\n",
    "![alt text](https://i.imgur.com/BTVYXQ1.jpg/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f_oWoN97BhDY"
   },
   "source": [
    "*  <font color='blue'><b> Write code for generating samples</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ph_6D2SDzz7F"
   },
   "outputs": [],
   "source": [
    "def generating_samples(input_data, target_data):\n",
    "\n",
    "    '''In this function, we will write code for generating 30 samples '''\n",
    "    \n",
    "    selected_rows = np.random.choice(len(input_data), 303, replace=False)\n",
    "    replacing_rows = np.random.choice(selected_rows, 203, replace=False)\n",
    "    \n",
    "        \n",
    "    number_of_columns_to_select = random.randint(3, 13)\n",
    "    selected_columns =  np.array(random.sample(range(0, 13), number_of_columns_to_select ))\n",
    "    \n",
    "    sample_data = input_data[selected_rows[:, None], selected_columns]\n",
    "    target_of_sample_data = target_data[selected_rows]\n",
    "\n",
    "    # replicating data\n",
    "    replicated_sample_data = input_data[replacing_rows[:, None], selected_columns]\n",
    "    target_of_replicated_sample_data = target_data[replacing_rows]\n",
    "\n",
    "    # concatenating data\n",
    "    final_sample_data = np.vstack((sample_data, replicated_sample_data))\n",
    "    target_of_sample_data = target_of_sample_data.reshape(-1,1)\n",
    "    target_of_replicated_sample_data = target_of_replicated_sample_data.reshape(-1,1)\n",
    "    final_target_data = np.vstack((target_of_sample_data,target_of_replicated_sample_data))\n",
    "\n",
    "    return final_sample_data , final_target_data, selected_rows, selected_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MivEQFlm7iOg"
   },
   "source": [
    "<font color='cyan'> <b> Grader function - 1 </b> </fongt>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AVvuhNzm7uld"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_samples(a,b,c,d):\n",
    "    length = (len(a)==506  and len(b)==506)\n",
    "    sampled = (len(a)-len(set([str(i) for i in a]))==203)\n",
    "    rows_length = (len(c)==303)\n",
    "    column_length= (len(d)>=3)\n",
    "    assert(length and sampled and rows_length and column_length)\n",
    "    return True\n",
    "a,b,c,d = generating_samples(x, y)\n",
    "grader_samples(a,b,c,d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b4LSsmn4Jn2_"
   },
   "source": [
    "*  <font color='blue'> <b>Create 30 samples </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3ec7MN6sL2BZ"
   },
   "source": [
    "![alt text](https://i.imgur.com/p8eZaWL.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XXlKWjCcBvTk"
   },
   "outputs": [],
   "source": [
    "# Use generating_samples function to create 30 samples \n",
    "# store these created samples in a list\n",
    "list_input_data =[]\n",
    "list_output_data =[]\n",
    "list_selected_row= []\n",
    "list_selected_columns=[]\n",
    "\n",
    "for i in range(0, 30):\n",
    "    a, b, c, d = generating_samples(x, y)\n",
    "    list_input_data.append(a)\n",
    "    list_output_data.append(b)\n",
    "    list_selected_row.append(c)\n",
    "    list_selected_columns.append(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MXUz9VFiMQkh"
   },
   "source": [
    "<font color='cyan'> <b>Grader function - 2 </b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hCvIq8NuMWOC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_30(a):\n",
    "    assert(len(a)==30 and len(a[0])==506)\n",
    "    return True\n",
    "grader_30(list_input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Pv-mkZkO6dh"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "whaHCPB0O8qF"
   },
   "source": [
    "<font color='red'><b>Step - 2 </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XBy4zXSWPtU8"
   },
   "source": [
    "<font color='orange'><b>Flowchart for building tree</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5xvH06HPQBdP"
   },
   "source": [
    "![alt text](https://i.imgur.com/pcXfSmp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WRwPO_uHQjul"
   },
   "source": [
    "*  <font color='blue'><b> Write code for building regression trees</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YWQp6tRwMthq"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "list_of_models = []\n",
    "\n",
    "for i in range(0, 30):\n",
    "    model = DecisionTreeRegressor(random_state=0, max_depth=None)\n",
    "    model.fit(list_input_data[i], list_output_data[i])\n",
    "    \n",
    "    list_of_models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DecisionTreeRegressor(random_state=0),\n",
       " DecisionTreeRegressor(random_state=0),\n",
       " DecisionTreeRegressor(random_state=0),\n",
       " DecisionTreeRegressor(random_state=0),\n",
       " DecisionTreeRegressor(random_state=0),\n",
       " DecisionTreeRegressor(random_state=0),\n",
       " DecisionTreeRegressor(random_state=0),\n",
       " DecisionTreeRegressor(random_state=0),\n",
       " DecisionTreeRegressor(random_state=0),\n",
       " DecisionTreeRegressor(random_state=0),\n",
       " DecisionTreeRegressor(random_state=0),\n",
       " DecisionTreeRegressor(random_state=0),\n",
       " DecisionTreeRegressor(random_state=0),\n",
       " DecisionTreeRegressor(random_state=0),\n",
       " DecisionTreeRegressor(random_state=0),\n",
       " DecisionTreeRegressor(random_state=0),\n",
       " DecisionTreeRegressor(random_state=0),\n",
       " DecisionTreeRegressor(random_state=0),\n",
       " DecisionTreeRegressor(random_state=0),\n",
       " DecisionTreeRegressor(random_state=0),\n",
       " DecisionTreeRegressor(random_state=0),\n",
       " DecisionTreeRegressor(random_state=0),\n",
       " DecisionTreeRegressor(random_state=0),\n",
       " DecisionTreeRegressor(random_state=0),\n",
       " DecisionTreeRegressor(random_state=0),\n",
       " DecisionTreeRegressor(random_state=0),\n",
       " DecisionTreeRegressor(random_state=0),\n",
       " DecisionTreeRegressor(random_state=0),\n",
       " DecisionTreeRegressor(random_state=0),\n",
       " DecisionTreeRegressor(random_state=0)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "21j8BKfAQ1U8"
   },
   "source": [
    "<font color='orange'><b>Flowchart for calculating MSE </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Q0mTBD2RBx_"
   },
   "source": [
    "![alt text](https://i.imgur.com/sPEE618.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6e-UamlHRjPy"
   },
   "source": [
    "After getting predicted_y for each data point, we can use sklearns mean_squared_error to calculate the MSE between predicted_y and actual_y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TnIMT7_oR312"
   },
   "source": [
    "*  <font color='blue'><b> Write code for calculating MSE</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qWhcvMRWRA9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506,)\n",
      "MSE :  0.10028320941507966\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from statistics import median\n",
    "\n",
    "array_of_Y = []\n",
    "\n",
    "for i in range(0, 30):\n",
    "    data_point_i = x[:, list_selected_columns[i]]\n",
    "    prediction = list_of_models[i].predict(data_point_i)\n",
    "    array_of_Y.append(prediction)\n",
    "    \n",
    "prediction_of_target = np.array(array_of_Y)\n",
    "prediction_of_target = prediction_of_target.transpose()\n",
    "\n",
    "median_predicted_target = np.median(prediction_of_target, axis=1)\n",
    "print(median_predicted_target.shape)\n",
    "\n",
    "print('MSE : ', mean_squared_error(y, median_predicted_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RuclPDMnSz8F"
   },
   "source": [
    "<font color='blue'><b>Step - 3 </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ESb9FSIDTM5V"
   },
   "source": [
    "<font color='orange'><b>Flowchart for calculating OOB score</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HB-d6NMETbd9"
   },
   "source": [
    "![alt text](https://i.imgur.com/95S5Mtm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WW3GOcFzTqbt"
   },
   "source": [
    "Now calculate the $OOB Score =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zBqcS03pUYSZ"
   },
   "source": [
    "*  <font color='blue'><b> Write code for calculating OOB score </b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fog_6DNdS-h_"
   },
   "outputs": [],
   "source": [
    "y_predicted_oob_median_list = []\n",
    "\n",
    "for i in range(0, 506):\n",
    "    indices_for_oob_models = []\n",
    "  \n",
    "    for index_oob in range(0, 30):\n",
    "        if i not in list_selected_row[index_oob]:\n",
    "            indices_for_oob_models.append(index_oob)\n",
    "      \n",
    "    y_predicted_oob_list = []\n",
    "  \n",
    "    for oob_model_index in indices_for_oob_models:\n",
    "        model_oob = list_of_models[oob_model_index]\n",
    "    \n",
    "        row_oob = x[i]\n",
    "\n",
    "        x_oob_data_point = [row_oob[columns] for columns in list_selected_columns[oob_model_index] ]\n",
    "        x_oob_data_point = np.array(x_oob_data_point).reshape(1, -1)\n",
    "\n",
    "        y_predicted_oob_data_point = model_oob.predict(x_oob_data_point)\n",
    "        y_predicted_oob_list.append(y_predicted_oob_data_point)\n",
    "    \n",
    "    y_predicted_oob_list = np.array(y_predicted_oob_list)\n",
    "  \n",
    "    y_predicted_median = np.median(y_predicted_oob_list)\n",
    "    y_predicted_oob_median_list.append(y_predicted_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB Score :  11.819754556053596\n"
     ]
    }
   ],
   "source": [
    "def calculate_oob_score(num_rows):\n",
    "    oob_score = 0\n",
    "    for i in range(0, num_rows):\n",
    "        oob_score += ((y[i] - y_predicted_oob_median_list[i] ) ** 2)\n",
    "    final_oob_score = oob_score/506\n",
    "    return final_oob_score\n",
    "\n",
    "print(\"OOB Score : \", calculate_oob_score(506))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sbuiwX3OUjUI"
   },
   "source": [
    "# <font color='blue'><b>Task 2</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ceW5-D88Uswi"
   },
   "outputs": [],
   "source": [
    "def OOB_35(x, y):\n",
    "    list_input_data       = []\n",
    "    list_output_data      = []\n",
    "    list_selected_row     = []\n",
    "    list_selected_columns = []\n",
    "\n",
    "    for i in range(0, 30):\n",
    "        a, b, c, d = generating_samples(x, y)\n",
    "        list_input_data.append(a)\n",
    "        list_output_data.append(b)\n",
    "        list_selected_row.append(c)\n",
    "        list_selected_columns.append(d)\n",
    "        \n",
    "    list_of_models = []\n",
    "\n",
    "    for i in range(0, 30):\n",
    "        model = DecisionTreeRegressor(random_state=0, max_depth=None)\n",
    "        model.fit(list_input_data[i], list_output_data[i])\n",
    "\n",
    "        list_of_models.append(model)\n",
    "        \n",
    "    array_of_Y = []\n",
    "\n",
    "    for i in range(0, 30):\n",
    "        data_point_i = x[:, list_selected_columns[i]]\n",
    "        prediction = list_of_models[i].predict(data_point_i)\n",
    "        array_of_Y.append(prediction)\n",
    "\n",
    "    prediction_of_target = np.array(array_of_Y)\n",
    "    prediction_of_target = prediction_of_target.transpose()\n",
    "\n",
    "    median_predicted_target = np.median(prediction_of_target, axis=1)\n",
    "\n",
    "    MSE = mean_squared_error(y, median_predicted_target)\n",
    "    \n",
    "    y_predicted_oob_median_list = []\n",
    "\n",
    "    for i in range(0, 506):\n",
    "        indices_for_oob_models = []\n",
    "\n",
    "        for index_oob in range(0, 30):\n",
    "            if i not in list_selected_row[index_oob]:\n",
    "                indices_for_oob_models.append(index_oob)\n",
    "\n",
    "        y_predicted_oob_list = []\n",
    "\n",
    "        for oob_model_index in indices_for_oob_models:\n",
    "            model_oob = list_of_models[oob_model_index]\n",
    "\n",
    "            row_oob = x[i]\n",
    "\n",
    "            x_oob_data_point = [row_oob[columns] for columns in list_selected_columns[oob_model_index] ]\n",
    "            x_oob_data_point = np.array(x_oob_data_point).reshape(1, -1)\n",
    "\n",
    "            y_predicted_oob_data_point = model_oob.predict(x_oob_data_point)\n",
    "            y_predicted_oob_list.append(y_predicted_oob_data_point)\n",
    "\n",
    "        y_predicted_oob_list = np.array(y_predicted_oob_list)\n",
    "\n",
    "        y_predicted_median = np.median(y_predicted_oob_list)\n",
    "        y_predicted_oob_median_list.append(y_predicted_median)\n",
    "        \n",
    "    oob_score = 0\n",
    "\n",
    "    for i in range(0, 506):\n",
    "        oob_score += (y[i] - y_predicted_oob_median_list[i] ) ** 2\n",
    "\n",
    "    final_oob_score = oob_score/506\n",
    "    \n",
    "    return MSE, final_oob_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final MSE :  0.03773221343873516\n",
      "Final OOB Score :  14.568117588932804\n"
     ]
    }
   ],
   "source": [
    "print('Final MSE : ', OOB_35(x, y)[0])\n",
    "print('Final OOB Score : ', OOB_35(x, y)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confidence_interval_mse_35  (0.05057493491638575, 0.1754684322888676)\n",
      "confidence_interval_oob_score_35  (13.081245166575794, 14.368479920707102)\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "mse_boston_35_times_arr = []\n",
    "oob_score_boston_35_times_arr = []\n",
    "\n",
    "for i in range(0, 35):\n",
    "    mse, oob_score = OOB_35(x, y)\n",
    "    mse_boston_35_times_arr.append(mse)\n",
    "    oob_score_boston_35_times_arr.append(oob_score)\n",
    "\n",
    "\n",
    "mse_boston_35_times_arr = np.array(mse_boston_35_times_arr)\n",
    "oob_score_boston_35_times_arr = np.array(oob_score_boston_35_times_arr)\n",
    "\n",
    "confidence_level = 0.95\n",
    "degrees_of_freedom = 34 \n",
    "\n",
    "mean_of_sample_mse_35 = np.mean(mse_boston_35_times_arr)\n",
    "standard_error_of_sample_mse_35 = scipy.stats.sem(mse_boston_35_times_arr)\n",
    "\n",
    "confidence_interval_mse_35 = scipy.stats.t.interval(confidence_level, degrees_of_freedom, mean_of_sample_mse_35, standard_error_of_sample_mse_35 )\n",
    "print(\"confidence_interval_mse_35 \", confidence_interval_mse_35)\n",
    "\n",
    "mean_of_sample_oob_score_35 = np.mean(oob_score_boston_35_times_arr)\n",
    "standard_error_of_sample_oob_score_35 = scipy.stats.sem(oob_score_boston_35_times_arr)\n",
    "\n",
    "confidence_interval_oob_score_35 = scipy.stats.t.interval(confidence_level, degrees_of_freedom, mean_of_sample_oob_score_35, standard_error_of_sample_oob_score_35 )\n",
    "print(\"confidence_interval_oob_score_35 \", confidence_interval_oob_score_35)\n",
    "\n",
    "# Source: https://www.kaggle.com/paulrohan2020/implementation-of-bootstrap-in-random-forest?scriptVersionId=68401562&cellId=23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jKTnJdiBVS_e"
   },
   "source": [
    "# <font color='blue'><b>Task 3</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eXxrvZqHV1Fr"
   },
   "source": [
    "<font color='orange'><b>Flowchart for Task 3</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NyjwEJ62V6a6"
   },
   "source": [
    "<b>Hint: </b> We created 30 models by using 30 samples in TASK-1. Here, we need send query point \"xq\"  to 30 models and perform the regression on the output generated by 30 models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0emSwLL7VurD"
   },
   "source": [
    "![alt text](https://i.imgur.com/Y5cNhQk.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "29hjwKlWWDfo"
   },
   "source": [
    "*  <font color='blue'><b> Write code for TASK 3 </b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i_pUlSD-VYD1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for query point :  19.15\n"
     ]
    }
   ],
   "source": [
    "def predicting_for_query(xq):\n",
    "    array_of_Y = []\n",
    "    \n",
    "    for i in range(0, 30):\n",
    "        model = list_of_models[i]\n",
    "\n",
    "        x_data_point = [xq[column] for column in list_selected_columns[i] ]\n",
    "        x_data_point = np.array(x_data_point).reshape(1, -1)\n",
    "\n",
    "        y_data_point = model.predict(x_data_point)\n",
    "        array_of_Y.append(y_data_point)\n",
    "\n",
    "    array_of_Y = np.array(array_of_Y)\n",
    "    y_predicted_median = np.median(array_of_Y)\n",
    "    \n",
    "    return y_predicted_median\n",
    "\n",
    "xq= [0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60]\n",
    "print('Prediction for query point : ', predicting_for_query(xq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DJHTGEZgWJjR"
   },
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IOdUi-0xWOJ9"
   },
   "source": [
    "<font color='red'><b>Write observations for task 1, task 2, task 3 indetail</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AIcax45hWKT-"
   },
   "source": [
    "### Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- \"Out of bag (OOB) score is a way of validating the Random forest model or even a tree based model.\" Just as Decision Trees, OOB score works very well with not so large datasets.\n",
    "- Here, to avoid loss of data, we only use those datapoints that weren't used in any specific sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 95% confidence interval means that the true value of our population mean lies in a given interval\n",
    "\n",
    "- Hence, (0.08313253560575587, 0.16148671907867237) contains the true population mean of MSE\n",
    "\n",
    "- (13.558069484773883, 14.711359352516423) contains the true population mean of OOB Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted value of our query point was found"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Bootstrap_assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
